<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta
			name="viewport"
			content="width=device-width, initial-scale=1.0"
		/>
		<meta
			http-equiv="Content-Security-Policy"
			content="upgrade-insecure-requests"
		/>

		<!-- Preload critical fonts -->
		<link
			rel="preconnect"
			href="https://fonts.googleapis.com"
		/>
		<link
			rel="preconnect"
			href="https://fonts.gstatic.com"
			crossorigin
		/>
		<link
			rel="preload"
			href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"
			as="style"
			onload="this.onload=null;this.rel='stylesheet'"
		/>
		<noscript
			><link
				rel="stylesheet"
				href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"
		/></noscript>

		<!-- SEO Meta Tags -->
		<title>A Practical Way to Think About RAG - Nick Karnik</title>
		<meta name="description" content="A grounded mental model for Retrieval-Augmented Generation, with two concrete examples and the tradeoffs that actually matter." />
		<link rel="canonical" href="https://nick.karnik.io/blog/how-rag-works" />

		<!-- Open Graph Meta Tags -->
		<meta property="og:title" content="A Practical Way to Think About RAG - Nick Karnik" />
		<meta property="og:description" content="A grounded mental model for Retrieval-Augmented Generation, with two concrete examples and the tradeoffs that actually matter." />
		<meta property="og:type" content="article" />
		<meta property="og:url" content="https://nick.karnik.io/blog/how-rag-works" />
		<meta property="og:image" content="https://nick.karnik.io/assets/images/blog/how-rag-works-cover.png" />
		<meta property="og:image:alt" content="A Practical Way to Think About RAG - Nick Karnik" />
		<meta property="og:image:width" content="1200" />
		<meta property="og:image:height" content="630" />
		<meta property="og:image:type" content="image/png" />
		<meta property="og:site_name" content="Nick Karnik" />
		<meta property="og:locale" content="en_US" />

		<!-- Twitter Card Meta Tags -->
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@theoutlander" />
		<meta name="twitter:creator" content="@theoutlander" />
		<meta name="twitter:title" content="A Practical Way to Think About RAG - Nick Karnik" />
		<meta name="twitter:description" content="A grounded mental model for Retrieval-Augmented Generation, with two concrete examples and the tradeoffs that actually matter." />
		<meta name="twitter:image" content="https://nick.karnik.io/assets/images/blog/how-rag-works-cover.png" />
		<meta name="twitter:image:alt" content="A Practical Way to Think About RAG - Nick Karnik" />

		<!-- Additional SEO Meta Tags -->
		<meta name="robots" content="index, follow" />
		<meta name="author" content="Nick Karnik" />
		<meta name="theme-color" content="#ffffff" />
		
		<!-- Article-specific meta tags -->
		<meta property="article:published_time" content="2025-12-12T10:00:00.000Z" />
		<meta property="article:modified_time" content="2025-12-12T10:00:00.000Z" />
		<meta property="article:author" content="https://nick.karnik.io" />
		<meta property="article:section" content="Technology" />
		<meta property="article:tag" content="Llm" />
		<meta property="article:tag" content="Rag" />
		<meta property="article:tag" content="Architecture" />
		
		
		<!-- Structured Data (JSON-LD) -->
		<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "A Practical Way to Think About RAG",
  "url": "https://nick.karnik.io/blog/how-rag-works",
  "datePublished": "2025-12-12T10:00:00.000Z",
  "dateModified": "2025-12-12T10:00:00.000Z",
  "description": "A grounded mental model for Retrieval-Augmented Generation, with two concrete examples and the tradeoffs that actually matter.",
  "image": "https://nick.karnik.io/assets/images/blog/how-rag-works-cover.png",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://nick.karnik.io/blog/how-rag-works"
  },
  "author": {
    "@type": "Person",
    "name": "Nick Karnik",
    "url": "https://nick.karnik.io"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Nick Karnik",
    "url": "https://nick.karnik.io",
    "logo": {
      "@type": "ImageObject",
      "url": "https://nick.karnik.io/assets/images/profile/nick-karnik.jpeg"
    }
  }
}
		</script>

		<!-- RSS Feed -->
		<link
			rel="alternate"
			type="application/rss+xml"
			title="RSS"
			href="https://nick.karnik.io/rss"
		/>

		<!-- Favicon -->
		<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2">
		<link rel="icon" type="image/png" sizes="32x32" href="/favicon_32x32.png?v=2">
		<link rel="icon" type="image/png" sizes="16x16" href="/favicon_16x16.png?v=2">

		<!-- Google Analytics: lazy loader to reduce unused JS on initial load -->
		<script>
			(function(){
				function loadGA(){
					if (window.__gaLoaded) return;
					window.__gaLoaded = true;
					var s = document.createElement('script');
					s.async = true;
					s.src = 'https://www.googletagmanager.com/gtag/js?id=G-62FC7BDSGJ';
					document.head.appendChild(s);
					window.dataLayer = window.dataLayer || [];
					window.gtag = function(){ dataLayer.push(arguments); };
					gtag('js', new Date());
					gtag('config', 'G-62FC7BDSGJ', { anonymize_ip: true });
				}
				// If user previously granted consent, load after idle; otherwise on first interaction
				var consent = null;
				try { consent = localStorage.getItem('ga_consent'); } catch (e) {}
				if (consent === 'granted') {
					(window.requestIdleCallback || function(cb){ setTimeout(cb, 2000); })(loadGA);
				} else {
					window.addEventListener('click', function onFirst(){ loadGA(); window.removeEventListener('click', onFirst, { capture: false }); }, { once: true, passive: true });
				}
			})();
		</script>

		

		<!-- External CSS -->
		<link rel="stylesheet" href="/styles.5fa86388.css" />
	</head>
	<body>
		<div id="root">
			<div class="bg_white min-h_100vh w_100% ov-x_hidden"><a href="#main-content" class="pos_absolute top_-40px left_6px bg_brand.600 c_white p_8px_12px td_none bdr_4px z_1000 fs_sm fw_medium trs_top_200ms_ease-in-out focus:top_6px focus:ring_2px_solid_white focus:ring-o_2px [@media_(prefers-reduced-motion:_reduce)]:trs_none">Skip to main content</a><header class="pos_sticky top_0 z_10 bg_white dark:bg_dark.surface bd-b_1px_solid bd-c_gray.200 bkdp_none md:bkdp_saturate(180%)_blur(8px) -webkit-backdrop-filter_none md:-webkit-backdrop-filter_saturate(180%)_blur(8px)"><div class="pos_relative max-w_6xl mx_auto px_4 md:px_6 lg:px_8 py_3"><div class="d_flex ai_center jc_space-between gap_6"><a href="/" class="td_none focus:ring_2px_solid_brand.600 focus:ring-o_2px focus:bdr_4px"><h1 class="fs_md fw_semibold c_gray.900 dark:c_dark.text ff_heading m_0">Nick Karnik</h1></a><nav class="d_flex ai_center gap_6" aria-label="Main navigation"><a href="/blog" aria-current="page" class="c_brand.600 fw_medium td_none p_8px_12px bdr_4px min-h_44px d_flex ai_center hover:c_brand.600 hover:td_underline focus:ring_2px_solid_brand.600 focus:ring-o_2px">Blog</a><a href="/about" class="c_gray.600 fw_normal td_none p_8px_12px bdr_4px min-h_44px d_flex ai_center hover:c_brand.600 hover:td_underline focus:ring_2px_solid_brand.600 focus:ring-o_2px">About</a><a href="/resume" class="c_gray.600 fw_normal td_none p_8px_12px bdr_4px min-h_44px d_flex ai_center hover:c_brand.600 hover:td_underline focus:ring_2px_solid_brand.600 focus:ring-o_2px">Resume</a><a href="/reviews" class="c_gray.600 fw_normal td_none p_8px_12px bdr_4px min-h_44px d_flex ai_center hover:c_brand.600 hover:td_underline focus:ring_2px_solid_brand.600 focus:ring-o_2px">Reviews</a><a href="/schedule" class="c_gray.600 fw_normal td_none p_8px_12px bdr_4px min-h_44px d_flex ai_center hover:c_brand.600 hover:td_underline focus:ring_2px_solid_brand.600 focus:ring-o_2px">Schedule</a></nav></div></div></header><main id="main-content" class="max-w_768px py_6 md:py_10 mx_auto px_4 md:px_6 w_100%"><article><header class="mb_8"><h1 class="fs_2xl md:fs_2.5rem fw_600 mb_4 c_#000 lh_1.2">A Practical Way to Think About RAG</h1><div class="d_flex ai_center gap_2 mb_6 fs_14px c_#666"><time>December 12, 2025</time><span>│</span><span>7<!-- --> <!-- -->min read</span><span>│</span><span>LLM</span></div><img src="/assets/images/blog/how-rag-works-cover.png" alt="A Practical Way to Think About RAG" loading="lazy" class="w_100% h_auto mb_6"/></header><div class="blog-post-content fs_16px md:fs_18px lh_1.7 c_#000 [&amp;_h2]:fs_1.5rem [&amp;_h2]:md:fs_1.75rem [&amp;_h2]:fw_600 [&amp;_h2]:mt_8 [&amp;_h2]:mb_4 [&amp;_h2]:c_#000 [&amp;_h3]:fs_1.25rem [&amp;_h3]:md:fs_1.5rem [&amp;_h3]:fw_600 [&amp;_h3]:mt_6 [&amp;_h3]:mb_3 [&amp;_h3]:c_#000 [&amp;_p]:mb_4 [&amp;_ul,_&amp;_ol]:mb_4 [&amp;_ul,_&amp;_ol]:pl_6 [&amp;_ol]:li-s_decimal_outside [&amp;_ol]:li-t_decimal [&amp;_ul]:li-s_disc_outside [&amp;_ul]:li-t_disc [&amp;_li]:mb_2 [&amp;_li]:d_list-item [&amp;_blockquote]:bd-l_3px_solid [&amp;_blockquote]:bd-c_#ccc [&amp;_blockquote]:pl_4 [&amp;_blockquote]:py_2 [&amp;_blockquote]:mb_4 [&amp;_blockquote]:font-style_italic [&amp;_blockquote]:c_#666 [&amp;_code]:bg_#f5f5f5 [&amp;_code]:px_2 [&amp;_code]:py_1 [&amp;_code]:bdr_3px [&amp;_code]:fs_0.9em [&amp;_code]:ff_mono [&amp;_pre]:bg_#f5f5f5 [&amp;_pre]:c_#000 [&amp;_pre]:p_3 [&amp;_pre]:md:p_4 [&amp;_pre]:bdr_3px [&amp;_pre]:ov_auto [&amp;_pre]:ov-x_auto [&amp;_pre]:mb_4 [&amp;_pre]:max-w_100% [&amp;_pre_code]:bg_transparent [&amp;_pre_code]:c_inherit [&amp;_pre_code]:px_0 [&amp;_pre_code]:py_0 [&amp;_a]:c_#000 [&amp;_a]:td_underline"><div><p>Retrieval-Augmented Generation (RAG) shows up constantly in conversations about LLM applications, especially once private or fast-changing data enters the picture. What I kept noticing was a gap between two kinds of explanations. Some stayed so abstract that it was hard to tell when RAG actually helped. Others jumped straight into tools and pipelines without first explaining what problem the system was really solving.</p>
<p>This is the mental model I keep coming back to when evaluating RAG systems. It is not exhaustive, but it is enough to make informed design decisions and to recognize when RAG is likely to help and when it is likely to cause problems.</p>
<h2>Why RAG exists</h2>
<p>Language models are strong at reasoning over text, but they operate inside a fixed knowledge boundary. They do not know your internal documents, policies, or product details unless those are explicitly provided at inference time. They also do not update themselves as your information changes.</p>
<p>When a question depends on knowledge outside the model’s training data, the model has no mechanism to retrieve it on its own. Without help, it fills in gaps using general patterns, which is often where hallucinations start.</p>
<p>RAG exists to address this limitation. It gives the model access to relevant external information at the moment it generates an answer, without retraining or fine-tuning the model itself.</p>
<p>That distinction matters. RAG does not make the model smarter. It makes the system more grounded.</p>
<h2>A useful way to think about it</h2>
<p>The simplest way to think about RAG is as a separation of responsibilities.</p>
<p>The model is responsible for reasoning, synthesis, and language. The system around it is responsible for deciding what information the model should see.</p>
<p>If you ask a question that depends on internal context, the quality of the answer depends almost entirely on whether the right reference material was placed in front of the model first. RAG is the mechanism that performs that selection.</p>
<p>Once you frame it this way, most debates about RAG become debates about retrieval quality rather than model behavior. It explains why systems can feel unreliable even when the model is doing its job.</p>
<h2>The basic flow, with emphasis on what matters</h2>
<p>Most RAG systems follow the same general pattern, but not all parts are equally important.</p>
<p>Documents are first split into chunks. These should be large enough to preserve meaning but small enough to be retrieved selectively. Chunking is one of the most underestimated parts of RAG, and it is where many systems quietly go wrong.</p>
<p>In practice, chunk boundaries often need to respect document structure, such as sections or paragraphs, rather than arbitrary token counts. Some overlap between chunks is also common, not to improve recall in theory, but to avoid cutting important context in half.</p>
<p>Each chunk is then converted into an embedding that represents its semantic meaning. When a user asks a question, the question is embedded as well, and the system retrieves the chunks that appear closest in meaning.</p>
<p>Embedding quality matters, but it rarely compensates for poor chunking or unclear queries. Most retrieval failures show up well before vector similarity becomes the limiting factor.</p>
<p>Those retrieved chunks are added to the prompt along with the user’s question. The model then generates a response based on that supplied context.</p>
<p>The loop itself is simple. The difficulty comes from making each step reliable under real data.</p>
<h2>A concrete example that usually works</h2>
<p>Imagine an internal policy document that covers refunds, eligibility criteria, timelines, and edge cases. A user asks, “Can customers get a refund after 30 days?”</p>
<p>With RAG, the retrieval step might surface three chunks: one defining eligibility, one describing standard timelines, and one listing exceptions. The model answers using those specific sections instead of relying on general knowledge about refunds.</p>
<p>If the answer is correct, it is because retrieval surfaced the right material. If it is wrong, the problem is almost always that an important chunk was missed or that irrelevant context crowded out the relevant one.</p>
<p>This pattern repeats across use cases.</p>
<h2>A second example, where RAG often fails</h2>
<p>A common failure case shows up in troubleshooting or operational knowledge bases.</p>
<p>Suppose you have a long document describing how to debug a production issue, including prerequisites, conditional steps, and warnings. A user asks a targeted question like, “Why does service X fail only after a config reload?”</p>
<p>Retrieval may return chunks that mention service X and config reloads, but miss a critical section explaining an ordering constraint or a hidden dependency. The model produces an answer that sounds reasonable, cites the retrieved context, and is still wrong in a way that is hard to detect.</p>
<p>This kind of failure is subtle. The system appears to work. The answer is coherent. But an important constraint was never retrieved, so the model could not reason about it.</p>
<p>This is one of the reasons RAG systems can feel unreliable in operational settings. They fail quietly when retrieval misses the one piece that actually matters.</p>
<h2>What RAG does well, and what it does not</h2>
<p>RAG works best when the task involves synthesizing information from a body of text that already contains the answer. It is well suited for policy questions, documentation lookup, and knowledge-based summarization.</p>
<p>It is much less effective when correctness depends on precise values, strict ordering, or full coverage of edge cases. In those situations, missing context is not a minor issue. It invalidates the answer.</p>
<p>This is also why prompt tuning rarely fixes weak RAG systems. If retrieval is off, prompting only rearranges the same incomplete inputs.</p>
<h2>When RAG is the wrong choice</h2>
<p>RAG is often treated as a default architecture, but in many cases it introduces more complexity than it removes.</p>
<p>If your dataset is small and stable, fine-tuning or even simple in-prompt examples may be more reliable. If the task requires deterministic outputs, structured extraction, or exact correctness, a rules-based or programmatic approach is usually safer.</p>
<p>RAG shines when the problem is about informed synthesis, not enforcement or computation.</p>
<h2>A simple way to visualize the system</h2>
<p>Here is the basic flow. Most complexity in real systems is layered on top of this, not a replacement for it.</p>
<img src="/assets/images/blog/rag-user-question-flow.svg" alt="drawing" width="200" style="display: block; margin: auto;"/>

<h3>What each step does:</h3>
<p><strong>User question</strong></p>
<p>Someone asks something like &quot;Can customers get a refund after 30 days?&quot; This triggers the RAG pipeline. The system needs to find relevant information to answer this specific question.</p>
<p><strong>Embed the question</strong></p>
<p>The question gets converted into a vector embedding that captures its semantic meaning. This is not about matching keywords. It is about what the question actually means. &quot;Refund policy for late requests&quot; and &quot;Can I get my money back after a month?&quot; would produce similar embeddings even though the words are different.</p>
<p><strong>Retrieve relevant chunks</strong></p>
<p>The system compares the question&#39;s embedding against all the chunks in your document store and finds the ones that are semantically closest. These are the chunks most likely to contain relevant information. This usually returns somewhere between 3 and 10 chunks.</p>
<p><strong>Add chunks to the prompt</strong></p>
<p>The retrieved chunks get inserted into the prompt along with the original question. Instead of just asking &quot;Can customers get a refund after 30 days?&quot;, the system is now asking &quot;Given these policy sections: [chunk 1, chunk 2, chunk 3], can customers get a refund after 30 days?&quot;</p>
<p><strong>Generate a response</strong></p>
<p>The model reads the question and the context chunks, then generates an answer. It does the same reasoning it always does, but now it has the specific information it needs. The quality of this answer depends almost entirely on whether retrieval found the right chunks.</p>
<h2>Closing</h2>
<p>Keeping this flow in mind helps keep systems understandable, even as more advanced techniques are layered on top.</p>
<p>RAG is best understood as a pattern, not a product or a feature. It is a way to control what information a language model sees at the moment it produces an answer.</p>
<p>Many modern systems layer additional techniques on top of this pattern, such as hybrid retrieval, reranking, or multi-step queries. These can improve results, but they do not change the underlying shape of the system. Retrieval still determines what the model can reason about. Generation determines how that reasoning is expressed.</p>
<p>As a starting point, this mental model is enough to decide whether RAG belongs in a system and where the real risks are. Once that’s clear, deeper implementation choices become easier to make and easier to question.</p>
</div></div><div class="mt_8 pt_6 bd-t_1px_solid bd-c_#e5e5e5"><div class="d_flex gap_2 flex-wrap_wrap"><span class="c_#666 fs_14px">Llm</span><span class="c_#666 fs_14px">Rag</span><span class="c_#666 fs_14px">Architecture</span></div></div></article><!--$!--><template></template><!--/$--></main><footer class="bg_white dark:bg_dark.surface bd-t_1px_solid bd-c_gray.200 dark:bd-c_dark.border pt_6 md:pt_10 pb_8 md:pb_10 mt_8"><div class="max-w_6xl mx_auto px_4 md:px_6 lg:px_8"><div class="d_flex md:d_grid flex-d_column md:flex-d_row md:grid-tc_1fr_1fr_1fr gap_2rem md:gap_2rem ai_flex-start md:ai_stretch"><div class="w_100% ta_center md:ta_left d_flex flex-d_column ai_center md:ai_flex-start pr_0 md:pr_2rem bd-r_none md:bd-r_1px_solid bd-c_transparent md:bd-c_gray.200 dark:bd-c_dark.border h_100% md:min-h_100%"><div class="fs_2.5rem md:fs_3.5rem fw_700 c_gray.900 dark:c_gray.100 lh_1.1 mb_1.5rem md:mb_2rem ls_-0.5px">Nick<br/>Karnik</div><div class="fs_1.75rem md:fs_xx-large lg:fs_medium c_gray.600 dark:c_gray.300 lh_1.8 mb_2rem md:mb_2rem fw_500">Engineering Leader – AI &amp; Product Strategy</div><div class="fs_0.9rem md:fs_0.95rem c_gray.700 dark:c_gray.300 mt_1rem md:mt_1.5rem lh_1.6">Available for consulting at<br/><a href="https://plutonicconsulting.com" target="_blank" rel="noopener" class="c_brand.600 td_none fw_600 cursor_url(&#x27;data:image/svg+xml;utf8,&lt;svg_xmlns=&quot;http://www.w3.org/2000/svg&quot;_width=&quot;20&quot;_height=&quot;20&quot;_viewBox=&quot;0_0_20_20&quot;&gt;&lt;circle_cx=&quot;10&quot;_cy=&quot;10&quot;_r=&quot;8&quot;_fill=&quot;%236366f1&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;path_d=&quot;M10_6V14M6_10H14&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;/svg&gt;&#x27;)_10_10,_pointer trs_color_0.2s_ease [@media_(prefers-reduced-motion:_reduce)]:trs_none hover:c_brand.700 focus:ring_2px_solid_brand.600 focus:ring-o_2px focus:bdr_4px">Plutonic Consulting</a></div><div class="fs_0.85rem md:fs_0.9rem c_gray.600 dark:c_gray.300 lh_1.6 mt_1.5rem md:mt_0.0.5rem pt_1.5rem md:pt_2rem bd-t_1px_solid bd-c_gray.200 dark:bd-c_dark.border">© <!-- -->2026<!-- --> <span class="fw_700 c_gray.900 dark:c_gray.100">Nick Karnik</span>. All rights reserved.</div></div><div class="w_100% ta_center md:ta_left d_flex flex-d_column ai_center md:ai_flex-start gap_0.5rem pr_0 md:pr_2rem bd-r_none md:bd-r_1px_solid bd-c_transparent md:bd-c_gray.200 dark:bd-c_dark.border"><a href="mailto:nick@karnik.io" class="d_flex ai_center gap_2 fs_sm c_gray.700 dark:c_dark.text td_none cursor_url(&#x27;data:image/svg+xml;utf8,&lt;svg_xmlns=&quot;http://www.w3.org/2000/svg&quot;_width=&quot;20&quot;_height=&quot;20&quot;_viewBox=&quot;0_0_20_20&quot;&gt;&lt;circle_cx=&quot;10&quot;_cy=&quot;10&quot;_r=&quot;8&quot;_fill=&quot;%236366f1&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;path_d=&quot;M10_6V14M6_10H14&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;/svg&gt;&#x27;)_10_10,_pointer min-h_44px md:min-h_auto px_0.5rem md:px_3 py_0.5rem md:py_2.5 bdr_4px md:bdr_md white-space_nowrap trs_all_200ms_ease-in-out [@media_(prefers-reduced-motion:_reduce)]:trs_none hover:c_brand.600 hover:td_underline active:trf_scale(0.98) active:md:trf_none focus:ring_2px_solid_brand.600 focus:ring-o_2px focus:bdr_4px focus:md:bdr_md [@media_(hover:_none)_and_(pointer:_coarse)]:min-h_44px [@media_(hover:_none)_and_(pointer:_coarse)]:px_0.5rem [@media_(hover:_none)_and_(pointer:_coarse)]:py_0.5rem"><div class="c_#000000 dark:c_#FFFFFF hover:c_#333333 hover:dark:c_#E4E4E7"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="18" width="18" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0z"></path><path d="M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4-8 5-8-5V6l8 5 8-5v2z"></path></svg></div><span>nick@karnik.io</span></a><a href="/assets/documents/resume-nick-karnik.pdf" target="_blank" rel="noopener" class="d_flex ai_center gap_2 fs_sm c_gray.700 dark:c_dark.text td_none cursor_url(&#x27;data:image/svg+xml;utf8,&lt;svg_xmlns=&quot;http://www.w3.org/2000/svg&quot;_width=&quot;20&quot;_height=&quot;20&quot;_viewBox=&quot;0_0_20_20&quot;&gt;&lt;circle_cx=&quot;10&quot;_cy=&quot;10&quot;_r=&quot;8&quot;_fill=&quot;%236366f1&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;path_d=&quot;M10_6V14M6_10H14&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;/svg&gt;&#x27;)_10_10,_pointer min-h_44px md:min-h_auto px_0.5rem md:px_3 py_0.5rem md:py_2.5 bdr_4px md:bdr_md white-space_nowrap trs_all_200ms_ease-in-out [@media_(prefers-reduced-motion:_reduce)]:trs_none hover:c_brand.600 hover:td_underline active:trf_scale(0.98) active:md:trf_none focus:ring_2px_solid_brand.600 focus:ring-o_2px focus:bdr_4px focus:md:bdr_md [@media_(hover:_none)_and_(pointer:_coarse)]:min-h_44px [@media_(hover:_none)_and_(pointer:_coarse)]:px_0.5rem [@media_(hover:_none)_and_(pointer:_coarse)]:py_0.5rem"><div class="c_#000000 dark:c_#FFFFFF hover:c_#333333 hover:dark:c_#E4E4E7"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" aria-hidden="true" height="18" width="18" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"></path></svg></div><span>Resume</span></a><a href="https://stackoverflow.com/users/460472/nick" target="_blank" rel="noopener" class="d_flex ai_center gap_2 fs_sm c_gray.700 dark:c_dark.text td_none cursor_url(&#x27;data:image/svg+xml;utf8,&lt;svg_xmlns=&quot;http://www.w3.org/2000/svg&quot;_width=&quot;20&quot;_height=&quot;20&quot;_viewBox=&quot;0_0_20_20&quot;&gt;&lt;circle_cx=&quot;10&quot;_cy=&quot;10&quot;_r=&quot;8&quot;_fill=&quot;%236366f1&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;path_d=&quot;M10_6V14M6_10H14&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;/svg&gt;&#x27;)_10_10,_pointer min-h_44px md:min-h_auto px_0.5rem md:px_3 py_0.5rem md:py_2.5 bdr_4px md:bdr_md white-space_nowrap trs_all_200ms_ease-in-out [@media_(prefers-reduced-motion:_reduce)]:trs_none hover:c_brand.600 hover:td_underline active:trf_scale(0.98) active:md:trf_none focus:ring_2px_solid_brand.600 focus:ring-o_2px focus:bdr_4px focus:md:bdr_md [@media_(hover:_none)_and_(pointer:_coarse)]:min-h_44px [@media_(hover:_none)_and_(pointer:_coarse)]:px_0.5rem [@media_(hover:_none)_and_(pointer:_coarse)]:py_0.5rem"><div class="c_#F48024 dark:c_#FFA366 hover:c_#D66D1A hover:dark:c_#FFB88C"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 384 512" height="18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M290.7 311L95 269.7 86.8 309l195.7 41zm51-87L188.2 95.7l-25.5 30.8 153.5 128.3zm-31.2 39.7L129.2 179l-16.7 36.5L293.7 300zM262 32l-32 24 119.3 160.3 32-24zm20.5 328h-200v39.7h200zm39.7 80H42.7V320h-40v160h359.5V320h-40z"></path></svg></div><span>Stack Overflow</span></a><a href="https://www.codementor.io/@theoutlander" target="_blank" rel="noopener" class="d_flex ai_center gap_2 fs_sm c_gray.700 dark:c_dark.text td_none cursor_url(&#x27;data:image/svg+xml;utf8,&lt;svg_xmlns=&quot;http://www.w3.org/2000/svg&quot;_width=&quot;20&quot;_height=&quot;20&quot;_viewBox=&quot;0_0_20_20&quot;&gt;&lt;circle_cx=&quot;10&quot;_cy=&quot;10&quot;_r=&quot;8&quot;_fill=&quot;%236366f1&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;path_d=&quot;M10_6V14M6_10H14&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;/svg&gt;&#x27;)_10_10,_pointer min-h_44px md:min-h_auto px_0.5rem md:px_3 py_0.5rem md:py_2.5 bdr_4px md:bdr_md white-space_nowrap trs_all_200ms_ease-in-out [@media_(prefers-reduced-motion:_reduce)]:trs_none hover:c_brand.600 hover:td_underline active:trf_scale(0.98) active:md:trf_none focus:ring_2px_solid_brand.600 focus:ring-o_2px focus:bdr_4px focus:md:bdr_md [@media_(hover:_none)_and_(pointer:_coarse)]:min-h_44px [@media_(hover:_none)_and_(pointer:_coarse)]:px_0.5rem [@media_(hover:_none)_and_(pointer:_coarse)]:py_0.5rem"><div class="c_#FF6B35 dark:c_#FF8C66 hover:c_#E55A2B hover:dark:c_#FFA380"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="w_18px h_18px flex-sh_0 c_currentColor d_block" style="width:18px;height:18px;color:currentColor"><desc>Codementor Streamline Icon: https://streamlinehq.com</desc><title>Codementor</title><path d="M8.487 14.887c0.39 0 0.706 0.314 0.706 0.7a0.703 0.703 0 0 1 -0.706 0.7H5.632a0.703 0.703 0 0 1 -0.707 -0.7c0 -0.386 0.317 -0.7 0.707 -0.7zm0.69 -2.593c0.39 0 0.706 0.315 0.706 0.7a0.703 0.703 0 0 1 -0.707 0.7H5.648a0.703 0.703 0 0 1 -0.706 -0.7c0 -0.386 0.316 -0.7 0.706 -0.7zm3.864 -3.46a2.109 2.109 0 0 1 2.118 -2.099 2.109 2.109 0 0 1 2.118 2.1 2.115 2.115 0 0 1 -2.118 2.103 2.116 2.116 0 0 1 -2.118 -2.104Zm6.259 6.559c0.1 0.619 -0.378 1.18 -1.005 1.178h-6.272a1.016 1.016 0 0 1 -1.005 -1.178c0.315 -1.942 1.391 -3.509 2.796 -4.13a2.768 2.768 0 0 0 2.69 0c1.405 0.621 2.482 2.19 2.796 4.13zm-8.712 -4.29c-8.38 0 -0.147 -0.002 -4.941 -0.002a0.703 0.703 0 0 1 -0.707 -0.7c0 -0.386 0.317 -0.7 0.707 -0.7l4.941 0.001c0.39 0 0.707 0.314 0.706 0.701a0.702 0.702 0 0 1 -0.706 0.7zm-4.94 -2.594a0.702 0.702 0 0 1 -0.707 -0.7c0 -0.386 0.317 -0.7 0.707 -0.7h4.94c0.389 0 0.705 0.313 0.705 0.7a0.703 0.703 0 0 1 -0.706 0.699zm7.809 10.117a0.658 0.658 0 0 0 0.66 -0.654h7.06v-12.6H2.824v12.599h7.059c0 0.361 0.295 0.654 0.66 0.654zM24 17.972v0.957c0 0.605 -0.496 1.096 -1.106 1.096H1.106c-0.61 0 -1.106 -0.49 -1.106 -1.096v-0.957h1.413V5.357c0 -0.763 0.623 -1.382 1.394 -1.382h18.387c0.77 0 1.394 0.619 1.394 1.382v12.615Z" fill="currentColor" stroke-width="1"></path></svg></div><span>Codementor</span></a></div><div class="w_100% ta_center md:ta_left d_flex flex-d_column ai_center md:ai_flex-start gap_0.5rem"><a href="https://github.com/theoutlander" target="_blank" rel="noopener" class="d_flex ai_center gap_2 fs_sm c_gray.700 dark:c_dark.text td_none cursor_url(&#x27;data:image/svg+xml;utf8,&lt;svg_xmlns=&quot;http://www.w3.org/2000/svg&quot;_width=&quot;20&quot;_height=&quot;20&quot;_viewBox=&quot;0_0_20_20&quot;&gt;&lt;circle_cx=&quot;10&quot;_cy=&quot;10&quot;_r=&quot;8&quot;_fill=&quot;%236366f1&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;path_d=&quot;M10_6V14M6_10H14&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;/svg&gt;&#x27;)_10_10,_pointer min-h_44px md:min-h_auto px_0.5rem md:px_3 py_0.5rem md:py_2.5 bdr_4px md:bdr_md white-space_nowrap trs_all_200ms_ease-in-out [@media_(prefers-reduced-motion:_reduce)]:trs_none hover:c_brand.600 hover:td_underline active:trf_scale(0.98) active:md:trf_none focus:ring_2px_solid_brand.600 focus:ring-o_2px focus:bdr_4px focus:md:bdr_md [@media_(hover:_none)_and_(pointer:_coarse)]:min-h_44px [@media_(hover:_none)_and_(pointer:_coarse)]:px_0.5rem [@media_(hover:_none)_and_(pointer:_coarse)]:py_0.5rem"><div class="c_#181717 dark:c_#FFFFFF hover:c_#000000 hover:dark:c_#E4E4E7"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></div><span>GitHub</span></a><a href="https://www.linkedin.com/in/theoutlander" target="_blank" rel="noopener" class="d_flex ai_center gap_2 fs_sm c_gray.700 dark:c_dark.text td_none cursor_url(&#x27;data:image/svg+xml;utf8,&lt;svg_xmlns=&quot;http://www.w3.org/2000/svg&quot;_width=&quot;20&quot;_height=&quot;20&quot;_viewBox=&quot;0_0_20_20&quot;&gt;&lt;circle_cx=&quot;10&quot;_cy=&quot;10&quot;_r=&quot;8&quot;_fill=&quot;%236366f1&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;path_d=&quot;M10_6V14M6_10H14&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;/svg&gt;&#x27;)_10_10,_pointer min-h_44px md:min-h_auto px_0.5rem md:px_3 py_0.5rem md:py_2.5 bdr_4px md:bdr_md white-space_nowrap trs_all_200ms_ease-in-out [@media_(prefers-reduced-motion:_reduce)]:trs_none hover:c_brand.600 hover:td_underline active:trf_scale(0.98) active:md:trf_none focus:ring_2px_solid_brand.600 focus:ring-o_2px focus:bdr_4px focus:md:bdr_md [@media_(hover:_none)_and_(pointer:_coarse)]:min-h_44px [@media_(hover:_none)_and_(pointer:_coarse)]:px_0.5rem [@media_(hover:_none)_and_(pointer:_coarse)]:py_0.5rem"><div class="c_#0A66C2 dark:c_#0A66C2 hover:c_#004182 hover:dark:c_#3399FF"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></div><span>LinkedIn</span></a><a href="https://x.com/theoutlander" target="_blank" rel="noopener" class="d_flex ai_center gap_2 fs_sm c_gray.700 dark:c_dark.text td_none cursor_url(&#x27;data:image/svg+xml;utf8,&lt;svg_xmlns=&quot;http://www.w3.org/2000/svg&quot;_width=&quot;20&quot;_height=&quot;20&quot;_viewBox=&quot;0_0_20_20&quot;&gt;&lt;circle_cx=&quot;10&quot;_cy=&quot;10&quot;_r=&quot;8&quot;_fill=&quot;%236366f1&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;path_d=&quot;M10_6V14M6_10H14&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;/svg&gt;&#x27;)_10_10,_pointer min-h_44px md:min-h_auto px_0.5rem md:px_3 py_0.5rem md:py_2.5 bdr_4px md:bdr_md white-space_nowrap trs_all_200ms_ease-in-out [@media_(prefers-reduced-motion:_reduce)]:trs_none hover:c_brand.600 hover:td_underline active:trf_scale(0.98) active:md:trf_none focus:ring_2px_solid_brand.600 focus:ring-o_2px focus:bdr_4px focus:md:bdr_md [@media_(hover:_none)_and_(pointer:_coarse)]:min-h_44px [@media_(hover:_none)_and_(pointer:_coarse)]:px_0.5rem [@media_(hover:_none)_and_(pointer:_coarse)]:py_0.5rem"><div class="c_#1DA1F2 dark:c_#1DA1F2 hover:c_#0d8bd9 hover:dark:c_#4db3f5"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg></div><span>Twitter</span></a><a href="https://youtube.com/@nick-karnik" target="_blank" rel="noopener" class="d_flex ai_center gap_2 fs_sm c_gray.700 dark:c_dark.text td_none cursor_url(&#x27;data:image/svg+xml;utf8,&lt;svg_xmlns=&quot;http://www.w3.org/2000/svg&quot;_width=&quot;20&quot;_height=&quot;20&quot;_viewBox=&quot;0_0_20_20&quot;&gt;&lt;circle_cx=&quot;10&quot;_cy=&quot;10&quot;_r=&quot;8&quot;_fill=&quot;%236366f1&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;path_d=&quot;M10_6V14M6_10H14&quot;_stroke=&quot;%23e2e8f0&quot;_stroke-width=&quot;1&quot;/&gt;&lt;/svg&gt;&#x27;)_10_10,_pointer min-h_44px md:min-h_auto px_0.5rem md:px_3 py_0.5rem md:py_2.5 bdr_4px md:bdr_md white-space_nowrap trs_all_200ms_ease-in-out [@media_(prefers-reduced-motion:_reduce)]:trs_none hover:c_brand.600 hover:td_underline active:trf_scale(0.98) active:md:trf_none focus:ring_2px_solid_brand.600 focus:ring-o_2px focus:bdr_4px focus:md:bdr_md [@media_(hover:_none)_and_(pointer:_coarse)]:min-h_44px [@media_(hover:_none)_and_(pointer:_coarse)]:px_0.5rem [@media_(hover:_none)_and_(pointer:_coarse)]:py_0.5rem"><div class="c_#FF0000 dark:c_#FF0000 hover:c_#CC0000 hover:dark:c_#FF4444"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 576 512" height="18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></div><span>YouTube</span></a></div></div></div></footer></div>
		</div>
		
		<script id="__POST_DATA__" type="application/json">{"id":"how-rag-works","slug":"how-rag-works","title":"A Practical Way to Think About RAG","date":"2025-12-12T10:00:00.000Z","cover":"/assets/images/blog/how-rag-works-cover.png","excerpt":"A grounded mental model for Retrieval-Augmented Generation, with two concrete examples and the tradeoffs that actually matter.","html":"\u003cp>Retrieval-Augmented Generation (RAG) shows up constantly in conversations about LLM applications, especially once private or fast-changing data enters the picture. What I kept noticing was a gap between two kinds of explanations. Some stayed so abstract that it was hard to tell when RAG actually helped. Others jumped straight into tools and pipelines without first explaining what problem the system was really solving.\u003c/p>\n\u003cp>This is the mental model I keep coming back to when evaluating RAG systems. It is not exhaustive, but it is enough to make informed design decisions and to recognize when RAG is likely to help and when it is likely to cause problems.\u003c/p>\n\u003ch2>Why RAG exists\u003c/h2>\n\u003cp>Language models are strong at reasoning over text, but they operate inside a fixed knowledge boundary. They do not know your internal documents, policies, or product details unless those are explicitly provided at inference time. They also do not update themselves as your information changes.\u003c/p>\n\u003cp>When a question depends on knowledge outside the model’s training data, the model has no mechanism to retrieve it on its own. Without help, it fills in gaps using general patterns, which is often where hallucinations start.\u003c/p>\n\u003cp>RAG exists to address this limitation. It gives the model access to relevant external information at the moment it generates an answer, without retraining or fine-tuning the model itself.\u003c/p>\n\u003cp>That distinction matters. RAG does not make the model smarter. It makes the system more grounded.\u003c/p>\n\u003ch2>A useful way to think about it\u003c/h2>\n\u003cp>The simplest way to think about RAG is as a separation of responsibilities.\u003c/p>\n\u003cp>The model is responsible for reasoning, synthesis, and language. The system around it is responsible for deciding what information the model should see.\u003c/p>\n\u003cp>If you ask a question that depends on internal context, the quality of the answer depends almost entirely on whether the right reference material was placed in front of the model first. RAG is the mechanism that performs that selection.\u003c/p>\n\u003cp>Once you frame it this way, most debates about RAG become debates about retrieval quality rather than model behavior. It explains why systems can feel unreliable even when the model is doing its job.\u003c/p>\n\u003ch2>The basic flow, with emphasis on what matters\u003c/h2>\n\u003cp>Most RAG systems follow the same general pattern, but not all parts are equally important.\u003c/p>\n\u003cp>Documents are first split into chunks. These should be large enough to preserve meaning but small enough to be retrieved selectively. Chunking is one of the most underestimated parts of RAG, and it is where many systems quietly go wrong.\u003c/p>\n\u003cp>In practice, chunk boundaries often need to respect document structure, such as sections or paragraphs, rather than arbitrary token counts. Some overlap between chunks is also common, not to improve recall in theory, but to avoid cutting important context in half.\u003c/p>\n\u003cp>Each chunk is then converted into an embedding that represents its semantic meaning. When a user asks a question, the question is embedded as well, and the system retrieves the chunks that appear closest in meaning.\u003c/p>\n\u003cp>Embedding quality matters, but it rarely compensates for poor chunking or unclear queries. Most retrieval failures show up well before vector similarity becomes the limiting factor.\u003c/p>\n\u003cp>Those retrieved chunks are added to the prompt along with the user’s question. The model then generates a response based on that supplied context.\u003c/p>\n\u003cp>The loop itself is simple. The difficulty comes from making each step reliable under real data.\u003c/p>\n\u003ch2>A concrete example that usually works\u003c/h2>\n\u003cp>Imagine an internal policy document that covers refunds, eligibility criteria, timelines, and edge cases. A user asks, “Can customers get a refund after 30 days?”\u003c/p>\n\u003cp>With RAG, the retrieval step might surface three chunks: one defining eligibility, one describing standard timelines, and one listing exceptions. The model answers using those specific sections instead of relying on general knowledge about refunds.\u003c/p>\n\u003cp>If the answer is correct, it is because retrieval surfaced the right material. If it is wrong, the problem is almost always that an important chunk was missed or that irrelevant context crowded out the relevant one.\u003c/p>\n\u003cp>This pattern repeats across use cases.\u003c/p>\n\u003ch2>A second example, where RAG often fails\u003c/h2>\n\u003cp>A common failure case shows up in troubleshooting or operational knowledge bases.\u003c/p>\n\u003cp>Suppose you have a long document describing how to debug a production issue, including prerequisites, conditional steps, and warnings. A user asks a targeted question like, “Why does service X fail only after a config reload?”\u003c/p>\n\u003cp>Retrieval may return chunks that mention service X and config reloads, but miss a critical section explaining an ordering constraint or a hidden dependency. The model produces an answer that sounds reasonable, cites the retrieved context, and is still wrong in a way that is hard to detect.\u003c/p>\n\u003cp>This kind of failure is subtle. The system appears to work. The answer is coherent. But an important constraint was never retrieved, so the model could not reason about it.\u003c/p>\n\u003cp>This is one of the reasons RAG systems can feel unreliable in operational settings. They fail quietly when retrieval misses the one piece that actually matters.\u003c/p>\n\u003ch2>What RAG does well, and what it does not\u003c/h2>\n\u003cp>RAG works best when the task involves synthesizing information from a body of text that already contains the answer. It is well suited for policy questions, documentation lookup, and knowledge-based summarization.\u003c/p>\n\u003cp>It is much less effective when correctness depends on precise values, strict ordering, or full coverage of edge cases. In those situations, missing context is not a minor issue. It invalidates the answer.\u003c/p>\n\u003cp>This is also why prompt tuning rarely fixes weak RAG systems. If retrieval is off, prompting only rearranges the same incomplete inputs.\u003c/p>\n\u003ch2>When RAG is the wrong choice\u003c/h2>\n\u003cp>RAG is often treated as a default architecture, but in many cases it introduces more complexity than it removes.\u003c/p>\n\u003cp>If your dataset is small and stable, fine-tuning or even simple in-prompt examples may be more reliable. If the task requires deterministic outputs, structured extraction, or exact correctness, a rules-based or programmatic approach is usually safer.\u003c/p>\n\u003cp>RAG shines when the problem is about informed synthesis, not enforcement or computation.\u003c/p>\n\u003ch2>A simple way to visualize the system\u003c/h2>\n\u003cp>Here is the basic flow. Most complexity in real systems is layered on top of this, not a replacement for it.\u003c/p>\n\u003cimg src=\"/assets/images/blog/rag-user-question-flow.svg\" alt=\"drawing\" width=\"200\" style=\"display: block; margin: auto;\"/>\n\n\u003ch3>What each step does:\u003c/h3>\n\u003cp>\u003cstrong>User question\u003c/strong>\u003c/p>\n\u003cp>Someone asks something like &quot;Can customers get a refund after 30 days?&quot; This triggers the RAG pipeline. The system needs to find relevant information to answer this specific question.\u003c/p>\n\u003cp>\u003cstrong>Embed the question\u003c/strong>\u003c/p>\n\u003cp>The question gets converted into a vector embedding that captures its semantic meaning. This is not about matching keywords. It is about what the question actually means. &quot;Refund policy for late requests&quot; and &quot;Can I get my money back after a month?&quot; would produce similar embeddings even though the words are different.\u003c/p>\n\u003cp>\u003cstrong>Retrieve relevant chunks\u003c/strong>\u003c/p>\n\u003cp>The system compares the question&#39;s embedding against all the chunks in your document store and finds the ones that are semantically closest. These are the chunks most likely to contain relevant information. This usually returns somewhere between 3 and 10 chunks.\u003c/p>\n\u003cp>\u003cstrong>Add chunks to the prompt\u003c/strong>\u003c/p>\n\u003cp>The retrieved chunks get inserted into the prompt along with the original question. Instead of just asking &quot;Can customers get a refund after 30 days?&quot;, the system is now asking &quot;Given these policy sections: [chunk 1, chunk 2, chunk 3], can customers get a refund after 30 days?&quot;\u003c/p>\n\u003cp>\u003cstrong>Generate a response\u003c/strong>\u003c/p>\n\u003cp>The model reads the question and the context chunks, then generates an answer. It does the same reasoning it always does, but now it has the specific information it needs. The quality of this answer depends almost entirely on whether retrieval found the right chunks.\u003c/p>\n\u003ch2>Closing\u003c/h2>\n\u003cp>Keeping this flow in mind helps keep systems understandable, even as more advanced techniques are layered on top.\u003c/p>\n\u003cp>RAG is best understood as a pattern, not a product or a feature. It is a way to control what information a language model sees at the moment it produces an answer.\u003c/p>\n\u003cp>Many modern systems layer additional techniques on top of this pattern, such as hybrid retrieval, reranking, or multi-step queries. These can improve results, but they do not change the underlying shape of the system. Retrieval still determines what the model can reason about. Generation determines how that reasoning is expressed.\u003c/p>\n\u003cp>As a starting point, this mental model is enough to decide whether RAG belongs in a system and where the real risks are. Once that’s clear, deeper implementation choices become easier to make and easier to question.\u003c/p>\n","url":"https://nick.karnik.io/blog/how-rag-works","tags":["LLM","RAG","Architecture"]}</script>
		<!-- Load client-side JavaScript bundle for routing -->
		<script type="module" src="/assets/index-HIQISN1u.js"></script>
		
		<!-- Dark mode detection script - DISABLED for mobile compatibility -->
		<!-- <script>
			// Check for saved theme preference or default to 'light'
			const theme = localStorage.getItem('theme') || 
				(window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light');
			
			// Apply theme immediately to prevent flash
			if (theme === 'dark') {
				document.documentElement.classList.add('dark');
			}
			
			// Listen for system theme changes
			window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', (e) => {
				if (!localStorage.getItem('theme')) {
					if (e.matches) {
						document.documentElement.classList.add('dark');
					} else {
						document.documentElement.classList.remove('dark');
					}
				}
			});
		</script> -->
	</body>
</html>